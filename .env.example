# ============================================================================
# Crawl4AI Web UI - Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your actual values
# ============================================================================

# ----------------------------------------------------------------------------
# Frontend Configuration
# ----------------------------------------------------------------------------

# Next.js will look for these in the container's environment
# These are set in docker-compose.yml, so you can override them there if needed
CRAWL4AI_BASE_URL=http://crawl4ai:11235
LITELLM_BASE_URL=http://litellm:4000
FILE_STORAGE_PATH=/app/data
OUTPUT_BASE_PATH=/app/data/output

# ----------------------------------------------------------------------------
# LiteLLM Proxy Configuration
# ----------------------------------------------------------------------------

# REQUIRED: Master key for LiteLLM proxy
# Generate a secure random string for production (use: openssl rand -hex 32)
LITELLM_MASTER_KEY=your-secure-random-master-key-here

# REQUIRED: Admin UI credentials
UI_USERNAME=your-username-here
UI_PASSWORD=your-secure-password-here

# Optional: Database URL for LiteLLM (SQLite by default)
# Uncomment and configure for PostgreSQL/MySQL in production
# DATABASE_URL=postgresql://user:password@localhost:5432/litellm

# ----------------------------------------------------------------------------
# LLM Provider API Keys
# ----------------------------------------------------------------------------
# Configure the providers you want to use
# Leave blank or remove the line if not using a particular provider

# OpenAI (REQUIRED if using OpenAI models)
OPENAI_API_KEY=

# Anthropic Claude (REQUIRED if using Claude models)
ANTHROPIC_API_KEY=

# z.AI GLM Models (REQUIRED if using z.AI)
# Note: Use z.ai endpoints, not ziphuai.cn
ZAI_API_KEY=
ZAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4

# LM Studio (local model server)
# Point to your LM Studio installation
# Use host.docker.internal to access host from Docker
LMSTUDIO_BASE_URL=http://host.docker.internal:1234/v1

# Google Gemini (REQUIRED if using Gemini models)
GEMINI_API_KEY=

# Groq (optional, for Groq models)
GROQ_API_KEY=

# ----------------------------------------------------------------------------
# GitHub Copilot (if using)
# ----------------------------------------------------------------------------
# Requires OAuth setup - see LiteLLM docs for details
# GITHUB_COPILOT_CLIENT_ID=
# GITHUB_COPILOT_CLIENT_SECRET=

# ----------------------------------------------------------------------------
# Additional Provider Configuration
# ----------------------------------------------------------------------------
# Add other providers as needed following the pattern:
# PROVIDER_NAME_API_KEY=your-api-key
# PROVIDER_NAME_BASE_URL=https://api.provider.com/v1

# ----------------------------------------------------------------------------
# Crawl4AI Configuration
# ----------------------------------------------------------------------------
# These are passed to the Crawl4AI container
# Most can be left as defaults

# Optional: Configure Crawl4AI-specific LLM keys if different from LiteLLM
# (Usually you'll use LiteLLM as the gateway, so these aren't needed)
# CRAWL4AI_OPENAI_API_KEY=
# CRAWL4AI_ANTHROPIC_API_KEY=

# ----------------------------------------------------------------------------
# Security Notes
# ----------------------------------------------------------------------------
# 1. NEVER commit .env to version control
# 2. Use strong passwords and API keys in production
# 3. Rotate keys regularly
# 4. Restrict network access to trusted IPs only
# 5. This setup assumes a trusted, single-user environment
#    For multi-user or public deployments, add authentication

# ----------------------------------------------------------------------------
# Quick Start Checklist
# ----------------------------------------------------------------------------
# [ ] Copy this file to .env
# [ ] Set LITELLM_MASTER_KEY to a secure random string
# [ ] Set UI_USERNAME and UI_PASSWORD
# [ ] Add API keys for the LLM providers you'll use
# [ ] Run: docker compose up -d
# [ ] Access frontend at http://localhost:3000
# [ ] Access LiteLLM UI at http://localhost:4000/ui
# [ ] Access Crawl4AI dashboard at http://localhost:11235/dashboard
